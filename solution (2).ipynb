{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mental Health Counseling Chatbot Using Django and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the librarys here\n",
    "import os as os\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "from enum import Enum\n",
    "import random as random\n",
    "import json as json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Create Classes for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define the RoleType Enum here\n",
    "class RoleType(Enum):\n",
    "    USER = 'user'\n",
    "    SYSTEM = 'system'\n",
    "    ASSISTANT = 'assistant'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Role class here\n",
    "class Role(object):\n",
    "    def __init__(self, role_type:RoleType, content):\n",
    "        self.role = role_type.value\n",
    "        self.content = content\n",
    "        self.value = {'role': self.role, 'content':self.content } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define the messsage class here\n",
    "class Message(object):\n",
    "    def __init__(self, user_content, system_content, assistant_content):\n",
    "        self.user_role = Role(role_type=RoleType.USER , content=user_content)\n",
    "        self.system_role = Role(role_type=RoleType.SYSTEM , content=system_content)\n",
    "        self.assistant_role = Role(role_type=RoleType.ASSISTANT, content=assistant_content)\n",
    "        self.message = {'messages':[self.system_role.value, self.user_role.value, self.assistant_role.value, ]} \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 : Load, Explore and Store the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\", split = 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Message object\n",
    "context = dataset[152]['Context']\n",
    "response = dataset[152]['Response']\n",
    "system_content = \"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\n",
    "message_obj = Message(user_content=context, system_content=system_content, assistant_content = response )\n",
    "\n",
    "print(message_obj.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create the train_dataset variable\n",
    "# Sample 100 items from the 'train' split\n",
    "sampled_dataset = random.choices(dataset, k=100)\n",
    "train_dataset = []\n",
    "\n",
    "# Print the sampled data to verify\n",
    "print(sampled_dataset[1])\n",
    "\n",
    "for row in sampled_dataset:\n",
    "    message_obj = Message(user_content=row['Context'], system_content=system_content, assistant_content=row['Response'])\n",
    "    train_dataset.append(message_obj.message)\n",
    "\n",
    "print(train_dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in JSONl format \n",
    "def save_to_jsonl(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for row in data:\n",
    "            line = json.dumps(row)\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "\n",
    "# Store the data in JSONL format\n",
    "training_data_path = '/usercode/data/train.jsonl'\n",
    "save_to_jsonl(train_dataset[:-5], training_data_path)\n",
    "\n",
    "validation_data_path = '/usercode/data/validation.jsonl'\n",
    "save_to_jsonl(train_dataset[-5:], validation_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 : Fine Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and validation files\n",
    "training_data = open(training_data_path, \"rb\")\n",
    "validation_data = open(validation_data_path, \"rb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=your_openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add OpenAI api_key\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training and validation files\n",
    "training_response = client.files.create(file=training_data, purpose=\"fine-tune\")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(file=validation_data, purpose=\"fine-tune\")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file id:\", training_file_id)\n",
    "print(\"Validation file id:\", validation_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fine-tuning job\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=\"my-test-model\",\n",
    "    validation_file=validation_file_id\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the job status\n",
    "job_id = response.id\n",
    "\n",
    "job_status = client.fine_tuning.jobs.retrieve(job_id)\n",
    "print(job_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 : Test the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and store message dictionaries\n",
    "system_message = \"\"\"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user's emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It's important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\"\"\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = \"Every winter I find myself getting sad because of the weather. How can I fight this?\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the fine-tuned chat completion model\n",
    "completion = client.chat.completions.create(\n",
    "    model= response.model,\n",
    "    messages=messages\n",
    ")\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and compare the output of the gpt-3.5-turbo chat completion model\n",
    "completion = client.chat.completions.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "print(completion.choices[0].message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Sep 11 2024, 16:02:53) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
