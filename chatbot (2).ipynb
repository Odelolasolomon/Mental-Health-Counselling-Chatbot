{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language models are at the core of natural language processing (NLP) tasks, providing the foundation for understanding and generating human-like text. They are statistical models trained on large amounts of text data to learn the patterns, relationships, and structures of language. By analyzing sequences of words, language models predict the likelihood of the next word in a given context.\n",
    "\n",
    "Language models are significant because they can comprehend and generate coherent text, enabling a wide range of applications such as text completion, summarization, translation, and conversational agents. They facilitate human-computer interaction, automate content creation, and assist in understanding and generating textual data across various domains.\n",
    "\n",
    "GPT models (Generative Pre-trained Transformer models) are a class of language models, the most famous of which is the GPT-3.5-turbo model developed by OpenAI, renowned for their ability to generate high-quality text across diverse tasks. GPT models are based on the transformer architecture, which consists of attention mechanisms and self-attention layers.\n",
    "\n",
    "The architecture of GPT models comprises several key components:\n",
    "\n",
    "Embedding layer: This converts input tokens into vector representations.\n",
    "\n",
    "Transformer encoder blocks: These comprise multiple layers of self-attention mechanisms followed by feedforward neural networks.\n",
    "\n",
    "Positional encoding: This incorporates positional information into the input embeddings to capture word order.\n",
    "\n",
    "Layer normalization and residual connections: This aids in stabilizing training and facilitating information flow through the network.\n",
    "\n",
    "Output layer: This generates probability distributions over the vocabulary to predict the next token in the sequence.\n",
    "\n",
    "The use case focuses on creating an accessible tool for managing mental health concerns. While this project uses OpenAI’s base capabilities, fine-tuning the model can enhance its performance by training it on specific datasets, making the chatbot even more effective in specialized contexts.\n",
    "\n",
    "In this project, you’ll use the dataset library to load your data and the openai library to train your model. The dataset for this project is provided in the /usercode/dataset/ directory; alternatively, you can load the dataset from the Hugging Face server. Once your model is trained, you’ll integrate it into a Django application to create a fully functional chatbot that interacts with users based on the model’s responses. Therefore, a Jupiter Notebook environment is provided on the right side.\n",
    "\n",
    "You’ll work in the /usercode/solution.ipyb file throughout the project. Each task in the project has one or more associated cells in the notebook that can be identified by their heading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll edit the /usercode/solution.ipynb file and import the following libraries:\n",
    "\n",
    "os: To interact with the file.\n",
    "\n",
    "load_dataset from datasets: To load the Mental Health Counseling Conversations database from the  Hugging Face.\n",
    "\n",
    "json: To work with JSON data.\n",
    "\n",
    "Enum from enum: To create an Enum class. It is used to define a set of symbolic names (members) bound to unique, constant values\n",
    "\n",
    "random: To select random instances from the data.\n",
    "\n",
    "OpenAI from openai: To work with OpenAI APIs.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Show Hint\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Use the following code to import the libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you’ll use OpenAI APIs that require the data to be defined in a special format like the one below:\n",
    "\n",
    "Ace Editor\n",
    "  \n",
    "In this task, you’ll edit the /usercode/solution.ipynb file and complete the following steps to later read the dataset in the desired format:\n",
    "\n",
    "Define an Enum class for RoleType.\n",
    "\n",
    "Create a Role class to represent a role and its associated content.\n",
    "\n",
    "Create a Message class to combine roles and their contents into a structured message.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "Use Python’s Enum to define a fixed set of role types (e.g., user, system, assistant). This helps in ensuring that the role types used throughout the code are consistent and predefined.\n",
    "Create a ‍‍‍Role‍‍ class to represent a role and its associated content. The Role class should accept a RoleType and some content. The RoleType should be converted to its corresponding string value when initializing the role. Store the role and content together in a dictionary to make them easy to access later.\n",
    "Create a Message class to combine roles and their contents into a structured message. The Message class should instantiate Role objects for each role type (user, system, assistant) and combine them into a single dictionary representing a complete message. This structure allows easy handling of multiple roles and their interactions.\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Add the following code to define an Enum class for RoleType:\n",
    "class RoleType(Enum):\n",
    "    USER = 'user'\n",
    "    SYSTEM = 'system'\n",
    "    ASSISTANT = 'assistant'\n",
    "Add the following code to create a Role class to represent a role and its associated content:\n",
    "class Role(object):\n",
    "    def __init__(self, role_type:RoleType, content):\n",
    "        self.role = role_type.value\n",
    "        self.content = content\n",
    "        self.value = {'role': self.role, 'content':self.content } \n",
    "Add the following code to create a Message class to combine roles and their contents into a structured message:\n",
    "class Message(object):\n",
    "    def __init__(self, user_content, system_content, assistant_content):\n",
    "        self.user_role = Role(role_type=RoleType.USER , content=user_content)\n",
    "        self.system_role = Role(role_type=RoleType.SYSTEM , content=system_content)\n",
    "        self.assistant_role = Role(role_type=RoleType.ASSISTANT, content=assistant_content)\n",
    "        self.message = {'messages':[s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection is a critical step in developing a language model because it directly impacts the model’s performance and capabilities. In this project, you’ll utilize the Mental Health Counseling Conversations HuggingFace dataset, which can be found in the usercode/data/mental_health_counseling_conversations directory. This dataset contains conversations about mental health counseling, which is relevant for training a ChatGPT clone to provide supportive and informative responses in similar contexts.\n",
    "\n",
    "As you can see in the box below, by examining the dataset, you’ll see that each row contains two features, Context and Response. For fine-tuning the model, you can use the Context feature for the user role and the Response feature for the assistant role\n",
    "\n",
    "Ace Editor\n",
    "  \n",
    "In this task, complete the following steps to edit the /usercode/solution.ipynb file:\n",
    "\n",
    "Load the dataset.\n",
    "\n",
    "Carefully craft the system’s role to offer mental health advice. Ensure it provides relevant and useful recommendations.\n",
    "\n",
    "Verify the system’s the response is as follows:\n",
    "\n",
    "Access the dataset to retrieve the user message and assistant response for a specific index, such as index 152 in the train set.\n",
    "\n",
    "Create a Message object with the user’s message, system message, and assistant’s response.\n",
    "\n",
    "Print the message attribute of the Message object to display the combined messages.\n",
    "\n",
    "Note: To ensure the health of the database, you can check the availability of Context and Response in the data rows and ignore the invalid ones.\n",
    "\n",
    "After confirming the sample output, convert the entire dataset to the desired format using these steps:\n",
    "\n",
    "Use random.choices() to randomly select 100 samples from the training data and assign them to sampled_dataset.\n",
    "\n",
    "Create an empty list train_dataset to store the processed messages.\n",
    "\n",
    "Loop through each row in the sampled_dataset:\n",
    "\n",
    "Create a Message object using Context as the user message, Response as the assistant message, and system_message as the system message.\n",
    "\n",
    "Append the message to the train_dataset.\n",
    "\n",
    "Print a sample message train_dataset to verify the conversion.\n",
    "\n",
    "By saving the data in a JSONL file, you’ll save time in the future because you won’t need to rerun the code to generate the file again. You can simply load the existing JSONL file whenever needed. For this, create a function save_to_jsonl() that takes two parameters: data (the dataset to be saved) and file_path (the file path where the JSONL data will be saved). In the function:\n",
    "\n",
    "Open the file specified file_path in write mode.\n",
    "\n",
    "Use a loop to iterate through each row in the data.\n",
    "\n",
    "For each row, convert it to a JSON string using json.dumps() and assign it to the variable line.\n",
    "\n",
    "Write the JSON string line to the file, followed by a newline character \\n, to create a new line for each JSON object.\n",
    "\n",
    "Define file paths for the training and validation datasets. These paths will be used as arguments when calling the save_to_jsonl() function.\n",
    "\n",
    "Call the save_to_jsonl() function twice: once for the train_dataset excluding the last 5 entries and once for the last 5 rows of the train_dataset (used as validation data).\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "Use the load_dataset() function from the datasets library with the appropriate repository and dataset name to load the desired dataset. You might need to handle any potential errors related to dataset availability or connectivity.\n",
    "You can use the following string to craft the role of system:\n",
    "system_message = \"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\n",
    "Access the relevant data from the dataset using the appropriate indexing:\n",
    "dataset[‘train’][<index_no>][‘Context’]: For the user’s message\n",
    "dataset[‘train’][<index_no>][‘Response’]: For the assistant’s message.\n",
    "Use the random.choices(<data>, k) function to sample from the validate_dataset, specifying the number of samples k you want to extract.\n",
    "Open the specified file path in write mode using the w flag.\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Use the following code to load the dataset:\n",
    "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\", split = 'train')\n",
    "Create a sample Message object to verify the system’s response as follows:\n",
    "context = dataset[152]['Context']\n",
    "response = dataset[152]['Response']\n",
    "system_content = \"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\n",
    "message_obj = Message(user_content=context, system_content=system_content, assistant_content = response )\n",
    "\n",
    "print(message_obj.message)\n",
    "Use the following code to create the data in the train_dataset variable:\n",
    "# Sample 100 items from the 'train' split\n",
    "sampled_dataset = random.choices(dataset, k=100)\n",
    "train_dataset = []\n",
    "\n",
    "# Print the sampled data to verify\n",
    "print(sampled_dataset[1])\n",
    "\n",
    "for row in sampled_dataset:\n",
    "    message_obj = Message(user_content=row['Context'], system_content=system_content, assistant_content=row['Response'])\n",
    "    train_dataset.append(message_obj.message)\n",
    "\n",
    "print(train_dataset[1])\n",
    "Use the following code to convert the dataset into JSONL format:\n",
    "def save_to_jsonl(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for row in data:\n",
    "            line = json.dumps(row)\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "\n",
    "# Store the data in JSONL format\n",
    "training_data_path = '/usercode/data/train.jsonl'\n",
    "save_to_jsonl(train_dataset[:-5], training_data_path)\n",
    "\n",
    "validation_data_path = '/usercode/data/validation.jsonl'\n",
    "save_to_jsonl(train_dataset[-5:], validation_data_path)\n",
    "\n",
    "Previous\n",
    "\n",
    "Com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning a pretrained language model is a crucial step for adapting it to specific tasks or domains, such as building a chatbot. In this task, you’ll fine-tune the model utilizing the training and validation data you prepared in Task 3. The model chosen for fine-tuning is GPT-3.5-turbo, provided by OpenAI through their API.\n",
    "\n",
    "Fine-tuning on OpenAI involves customizing a pretrained model GPT-3.5 or GPT-4 by training it on a specific, relevant dataset to adapt it for a particular task. The process includes preparing and formatting the data, uploading it via the OpenAI API, and running a fine-tuning job where the model learns from the new data. The fine-tuned model is then evaluated and adjusted as needed before being deployed for use in production, allowing for enhanced performance in specialized applications.\n",
    "\n",
    "In this task, complete the following steps to edit the /usercode/solution.ipynb file:\n",
    "\n",
    "Open the training and validation JSONL data files in binary read mode.\n",
    "\n",
    "Set up the OpenAI client. Initialize the OpenAI client with the API key.\n",
    "\n",
    "Upload the training data file to the OpenAI API for fine-tuning.\n",
    "\n",
    "Use the client.files.create() method to upload the training data file.\n",
    "\n",
    "Specify the purpose of the file upload as \"fine-tune\".\n",
    "\n",
    "Retrieve the ID of the uploaded training file.\n",
    "\n",
    "Repeat the above three steps for the validation data file and display the IDs of the uploaded training and validation files for confirmation.\n",
    "\n",
    "Use the client.fine_tuning.jobs.create() method to create a fine-tuning job.\n",
    "\n",
    "In the arguments, specify the training file ID and model name (e.g., gpt-3.5-turbo), a suffix for the model, and the validation file ID.\n",
    "\n",
    "Display the response from the fine-tuning job creation.\n",
    "\n",
    "To check the status of the fine-tuning job, retrieve the status of the fine-tuning job using its ID and display the status. Fine-tuning can take anywhere from a few minutes to several hours, depending on the size of your dataset and the complexity of the model.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "Open a file using the open() function.\n",
    "Pass the file name and the flag rb as arguments to read the file in binary read mode.\n",
    "Obtain an API key from the OpenAI website or dashboard. If you already have one, that’s great!\n",
    "Instantiate the OpenAI class, passing the API key as an argument to the api_key parameter.\n",
    "Use the client.files.create() method to upload files to the OpenAI API.\n",
    "Provide the file object as the file parameter and specify the purpose as fine-tune.\n",
    "Extract the file IDs from the response objects using the id attribute\n",
    "Utilize the client.fine_tuning.jobs.create() method to initiate a new fine-tuning job. Provide the training and validation file IDs, the desired model gpt-3.5-turbo, and any additional parameters, such as the suffix.\n",
    "Extract the job ID from the response object using the id attribute\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Use the following code to load the training and validation files:\n",
    "training_data = open(training_data_path, \"rb\")\n",
    "validation_data = open(validation_data_path, \"rb\")\n",
    "Access OpenAI’s API as follows:\n",
    "api_key = '<your_api_key>'\n",
    "client = OpenAI(api_key=api_key)\n",
    "Upload the training and validation files to the API as follows:\n",
    "training_response = client.files.create(file=training_data, purpose=\"fine-tune\")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(file=validation_data, purpose=\"fine-tune\")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file id:\", training_file_id)\n",
    "print(\"Validation file id:\", validation_file_id)\n",
    "Note: This code interacts with the client’s API to upload training and validation data files to fine-tune a model.\n",
    "\n",
    "Use the following code to create a fine-tuning job:\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=\"my-test-model\",\n",
    "    validation_file=validation_file_id\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(response)\n",
    "Use the following code to retrieve the job status:\n",
    "job_id = response.id\n",
    "\n",
    "job_status = client.fine_tuning.jobs.retrieve(job_id)\n",
    "print(job_status)\n",
    "Note: You also need the model value (a unique string name) to integrate it with Django in Task 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your model has been fine-tuned, it’s crucial to test its performance and verify that it works as expected. The following steps will guide you through testing the fine-tuned model with OpenAI’s API.\n",
    "\n",
    "To test and experiment with your fine-tuned model, create a data sample with the same format, exactly as in the load data stage. For this purpose, you do not need the assistant role. You can even use one of the same data samples.\n",
    "\n",
    "Initialize an empty list named messages to store message dictionaries.\n",
    "\n",
    "For the system’s message, create a dictionary representing the system message with the keys “role” and “content” and assign the system_message to the “content” key. Lastly, append this dictionary to the messages list.\n",
    "\n",
    "For the user’s Message, define the user_message string. Then, create a dictionary representing the user message with the keys “role” and “content,” assign them user_message to the “content” key, and append this dictionary to the messages list.\n",
    "\n",
    "Now compare the original and fine-tuned chat completion models as follows:\n",
    "\n",
    "For the fine-tuned chat completion model:\n",
    "\n",
    "Use the client.chat.completions.create() method to make a chat completion API call.\n",
    "\n",
    "Provide the fine-tuned model’s ID available against fine_tuned_model field name (in the output of the Task 4) and the conversation messages, messages, as arguments to this method.\n",
    "\n",
    "Extract and display the assistant’s reply generated by the chat completion model.\n",
    "\n",
    "Repeat the same steps for the \"gpt-3.5-turbo\" model.\n",
    "\n",
    "Compare the outputs of both models.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "Use the client.fine_tuning.jobs.retrieve() method to retrieve the status of the fine-tuning job.\n",
    "Pass the job ID as an argument to this method.\n",
    "Use the client.chat.completions.create() method to generate completions for the conversation.\n",
    "Provide the fine-tuned model ID and the conversation messages, messages, as arguments to this method.\n",
    "Extract the assistant’s reply using the following command:\n",
    "<completion_chat_object>.choices[0].message\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Use the following code to create and store message dictionaries:\n",
    "system_message = \"\"\"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user's emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It's important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\"\"\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = \"Every winter I find myself getting sad because of the weather. How can I fight this?\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "Once the job_status displayed in the Task 4 shows success in the status field, you can test the fine-tuned chat completion model by the model field as follows:\n",
    "completion = client.chat.completions.create(\n",
    "    model= response.model,\n",
    "    messages=messages\n",
    ")\n",
    "print(completion.choices[0].message)\n",
    "Obtain and compare the output of the gpt-3.5-turbo chat completion model with the fine-tuned model using the following code:\n",
    "completion = client.chat.completions.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "print(completion.choices[0].message)\n",
    "\n",
    "Previous\n",
    "\n",
    "Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll create a simple Django-based chatbot that uses OpenAI’s API for responses. You’ll integrate the API with the prepared Django project, design a basic user interface, configure routing, and run the server to test the chatbot.\n",
    "\n",
    "The following steps will guide you in creating a simple web app using Django and OpenAI’s API to build a chatbot. Here’s a high-level overview of the necessary actions:\n",
    "\n",
    "Connect prepared Django chatbot to OpenAI trained model:\n",
    "\n",
    "To enable AI-driven responses by integrating OpenAI’s API to process user input and generate responses.\n",
    "\n",
    "Create HTML templates for the frontend:\n",
    "\n",
    "Set up a basic HTML template to display the chatbot interface.\n",
    "\n",
    "Configure URL routing:\n",
    "\n",
    "Set up URL routes for the chatbot page and form submission.\n",
    "\n",
    "Run the Django server:\n",
    "\n",
    "Start the Django development server and test the chatbot.\n",
    "\n",
    "In the next few tasks, let’s go through each step in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll integrate the OpenAI API with your Django chatbot to enable interactions with the trained model. This will involve securely adding the API key to your Django project and creating a view to manage the interaction between the user and the trained model, allowing the chatbot to generate responses based on the AI model.\n",
    "\n",
    "In this task, you’ll integrate OpenAI’s API into your Django app to handle chatbot interactions.\n",
    "\n",
    "Add OpenAI’s API key to your project.\n",
    "\n",
    "Securely store and access the API key within the Django project to authenticate your application when interacting with OpenAI’s servers.\n",
    "\n",
    "Create a view to handle chatbot interactions with the trained model.\n",
    "\n",
    "Develop a Django view that takes user input, sends it to the OpenAI API, and returns the chatbot’s response based on the trained model, facilitating interaction between the user and the AI-powered chatbot.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "You’ll need to securely store and access your OpenAI API key in your Django app. Consider using environment variables for better security.\n",
    "Your view should handle POST requests containing user input, send this input to the trained model with openAI API, and return the response. Note that you should use the model name that you received in the Task 4.\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Run the following terminal command In the root of your Django project (where manage.py is located), to create a .env file\n",
    "touch .env\n",
    "Open the .env file and add your API_key\n",
    "OPENAI_API_KEY='API-KEY'\n",
    "Add the following code in /usercode/chatbot_project/chatbot_project/settings.py to load the API_KEY from the .env file:\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "In /usercode/chatbot_project/chatbot/views.py, add the following code:\n",
    "Note: Be careful! In the code, you must use the name of the model that you received from OpenAI in Task 4.\n",
    "\n",
    "from django.shortcuts import render\n",
    "from django.http import JsonResponse\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def chatbot_response(request):\n",
    "    if request.method == 'POST':\n",
    "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        user_input = request.POST.get('user_input')\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_input,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        chatbot_reply = response.choices[0].message.content \n",
    "        return JsonResponse({'reply': chatbot_reply})\n",
    "    return render(request, 'chat.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll design the visual structure of your Django chatbot by creating HTML templates. These templates will define how users interact with the chatbot on your web page, providing the layout and design necessary for the user interface.\n",
    "\n",
    "Create a base template.\n",
    "\n",
    "Establish a reusable structure that contains common elements (e.g., headers, footers, navigation) across different pages, ensuring consistency in your web application design.\n",
    "\n",
    "Create a chatbot interface template.\n",
    "\n",
    "Design the specific layout for the chatbot interface, where users will interact with the chatbot, send messages, and receive responses.\n",
    "\n",
    "Ensure the templates directory is configured.\n",
    "\n",
    "Verify that Django is correctly configured to locate and render your templates by setting the correct path in the project’s settings file. This ensures that the templates load properly when the application runs.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "A base template typically includes common elements like the <head> section and navigation menus, which other templates can extend.\n",
    "Use the extends tag to inherit from the base template and the block tags to insert specific content.\n",
    "Verify the /usercode/chatbot_project/chatbot_project/settings.py file to ensure the TEMPLATES setting includes the /usercode/chatbot_project/chatbot/template DIRS path.\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Create a templates folder in the /usercode/chatbot_project/chatbot_project/chatbot directory.\n",
    "Create the file base.html in the /usercode/chatbot_project/chatbot_project/chatbot/templates/base.html directory with the following code:\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>{% block title %}Chatbot{% endblock %}</title>\n",
    "    <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "    {% block content %}\n",
    "    {% endblock %}\n",
    "</body>\n",
    "</html>\n",
    "Create the chat.html file in the /usercode/chatbot_project/chatbot_project/chatbot/templates/chatbot/chat.html with the following code:\n",
    "{% extends 'base.html' %}\n",
    "\n",
    "{% block title %}Chatbot Interface{% endblock %}\n",
    "\n",
    "{% block content %}\n",
    "<h1 style=\"text-align: center;\">Chatbot</h1>\n",
    "\n",
    "\n",
    "<div id=\"chatArea\" style=\"border: 1px solid #ccc; border-radius: 10px; padding: 15px; height: 400px; overflow-y: auto; background-color: #f5f5f5; margin-bottom: 10px;\"></div>\n",
    "\n",
    "\n",
    "<form id=\"chatForm\" style=\"display: flex;\">\n",
    "    <input type=\"text\" id=\"userInput\" placeholder=\"Type your message here...\" aria-label=\"Type your message here\" style=\"flex: 1; padding: 10px; border-radius: 20px; border: 1px solid #ccc; font-size: 16px; outline: none;\">\n",
    "    <button type=\"submit\" style=\"padding: 10px 20px; margin-left: 10px; border: none; border-radius: 20px; background-color: #007bff; color: white; font-size: 16px; cursor: pointer;\">Send</button>\n",
    "</form>\n",
    "\n",
    "<script>\n",
    "    $(document).ready(function(){\n",
    "        \n",
    "        function scrollToBottom() {\n",
    "            $('#chatArea').scrollTop($('#chatArea')[0].scrollHeight);\n",
    "        }\n",
    "\n",
    "\n",
    "        function appendMessage(sender, message, isUser) {\n",
    "            const chatBubble = $('<div>').addClass('chat-bubble').text(message);\n",
    "            const chatWrapper = $('<div>').addClass('chat-message').append(chatBubble);\n",
    "\n",
    "\n",
    "            if (isUser) {\n",
    "                chatWrapper.css({'text-align': 'right'});\n",
    "                chatBubble.css({'background-color': '#007bff', 'color': 'white', 'border-radius': '15px 15px 0 15px'});\n",
    "            } else {\n",
    "                chatBubble.css({'background-color': '#eaeaea', 'color': '#333', 'border-radius': '15px 15px 15px 0'});\n",
    "            }\n",
    "\n",
    "            $('#chatArea').append(chatWrapper);\n",
    "            scrollToBottom();\n",
    "        }\n",
    "\n",
    "        $('#chatForm').on('submit', function(event){\n",
    "            event.preventDefault();\n",
    "\n",
    "\n",
    "            var userInput = $('#userInput').val().trim();\n",
    "\n",
    "\n",
    "            if (!userInput) {\n",
    "                alert('Please enter a message.');\n",
    "                return;\n",
    "            }\n",
    "\n",
    "\n",
    "            appendMessage('You', userInput, true);\n",
    "\n",
    "\n",
    "            $('#userInput').prop('disabled', true);\n",
    "            $('button[type=\"submit\"]').prop('disabled', true);\n",
    "\n",
    "\n",
    "            $.ajax({\n",
    "                url: '',\n",
    "                type: 'POST',\n",
    "                data: {\n",
    "                    'user_input': userInput,\n",
    "                    'csrfmiddlewaretoken': '{{ csrf_token }}'\n",
    "                },\n",
    "                success: function(response){\n",
    "\n",
    "                    appendMessage('Bot', response.reply, false);\n",
    "                    $('#userInput').val(''); \n",
    "                    $('#userInput').focus();  \n",
    "                },\n",
    "                error: function(){\n",
    "                    alert('Something went wrong. Please try again.');\n",
    "                },\n",
    "                complete: function() {\n",
    "\n",
    "                    $('#userInput').prop('disabled', false);\n",
    "                    $('button[type=\"submit\"]').prop('disabled', false);\n",
    "                }\n",
    "            });\n",
    "        });\n",
    "    });\n",
    "</script>\n",
    "\n",
    "\n",
    "<style>\n",
    "    .chat-message {\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .chat-bubble {\n",
    "        display: inline-block;\n",
    "        padding: 10px 15px;\n",
    "        max-width: 70%;\n",
    "        word-wrap: break-word;\n",
    "        font-size: 16px;\n",
    "    }\n",
    "</style>\n",
    "{% endblock %}\n",
    "In /usercode/chatbot_project/chatbot_project/settings.py, ensure the DIRS option in the TEMPLATES setting includes the path to your templates:\n",
    "import os\n",
    "\n",
    "TEMPLATES = [\n",
    "    {\n",
    "        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n",
    "        'DIRS': [os.path.join(BASE_DIR, 'chatbot', 'templates')],\n",
    "        'APP_DIRS': True,\n",
    "        'OPTIONS': {\n",
    "            'context_processors': [\n",
    "                'django.template.context_processors.debug',\n",
    "                'django.template.context_processors.request',\n",
    "                'django.contrib.auth.context_processors.auth',\n",
    "                'django.contrib.messages.context_processors.messages',\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll set up the URL routing for your Django project. This step ensures that the user can access the chatbot interface and submit input to the backend. URL routing links frontend interactions with backend logic, making the application functional.\n",
    "\n",
    "Define app-level URLs.\n",
    "\n",
    "Create specific URL patterns for your Django app that map to the views handling chatbot interactions. This allows the chatbot interface to be accessible via a URL.\n",
    "\n",
    "Include app-level URLs in project URLs.\n",
    "\n",
    "Connect the app’s URL patterns to the main project’s URL configuration so that the app’s functionality is accessible through the main application.\n",
    "\n",
    "Set up CSRF token handling.\n",
    "\n",
    "Enable CSRF protection for form submissions to prevent malicious attacks. This ensures that only trusted requests are processed by the server, enhancing security.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "Use Django’s path function to define URL patterns that map to your app’s views. These patterns should be added in the app’s /usercode/chatbot_project/app_name/urls.py file.\n",
    "Modify the project’s /usercode/chatbot_project/chatbot_project/urls.py file to include the URL patterns defined in the app’s /usercode/chatbot_project/app_name/urls.py file using the include function.\n",
    "Django requires a CSRF token to be included with POST requests for security reasons. Make sure your form includes this token.\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "Create the file urls.py in the /usercode/chatbot_project/chatbot/urls.py directory and add the following code:\n",
    "from django.urls import path\n",
    "from .views import chatbot_response\n",
    "\n",
    "urlpatterns = [\n",
    "    path('', chatbot_response, name='chatbot'),\n",
    "]\n",
    "Open the /usercode/chatbot_project/chatbot_project/urls.py file and update it as follows:\n",
    "from django.contrib import admin\n",
    "from django.urls import path, include\n",
    "\n",
    "urlpatterns = [\n",
    "    path('admin/', admin.site.urls),\n",
    "    path('', include('chatbot.urls')),\n",
    "]\n",
    "In the /usercode/chatbot_project/chatbot/templates/chat.html file, ensure the form includes the CSRF token:\n",
    "<form id=\"chatForm\" style=\"display: flex;\">\n",
    "    <input type=\"text\" id=\"userInput\" placeholder=\"Type your message here...\" aria-label=\"Type your message here\" style=\"flex: 1; padding: 10px; border-radius: 20px; border: 1px solid #ccc; font-size: 16px; outline: none;\">\n",
    "    <input type=\"hidden\" name=\"csrfmiddlewaretoken\" value=\"{{ csrf_token }}\">\n",
    "    <button type=\"submit\" style=\"padding: 10px 20px; margin-left: 10px; border: none; border-radius: 20px; background-color: #007bff; color: white; font-size: 16px; cursor: pointer;\">Send</button>\n",
    "</form>\n",
    "\n",
    "Previous\n",
    "\n",
    "Completed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll launch the Django development server to test the functionality of your chatbot application. By running the server, you will be able to interact with the chatbot in a browser and verify that all components are working as expected.\n",
    "\n",
    "Apply database migrations.\n",
    "\n",
    "Ensure that all database changes are applied, creating the necessary tables and structures for your Django app to function properly.\n",
    "\n",
    "Start the development server.\n",
    "\n",
    "Launch the Django development server to make your application accessible via a web browser. This will allow you to test the chatbot and interact with it in real time.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "Hide Hint\n",
    "Before starting the server, you need to apply migrations to create the database tables required by Django. Use the migrate command to set up the database schema.\n",
    "Use the runserver command to start the development server, which listens for incoming requests and serves your project.\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Hide Solution\n",
    "In your terminal, navigate to the project directory and run the following code:\n",
    "python3 manage.py migrate\n",
    "Run the following command and run the server:\n",
    "python3 manage.py runserver\n",
    "Now, you should be able to see the server running in the browser window in the workplace.\n",
    "\n",
    "\n",
    "Previous\n",
    "\n",
    "Comple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Sep 11 2024, 16:02:53) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
